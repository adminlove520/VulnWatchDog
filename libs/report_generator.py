import os
import xml.etree.ElementTree as ET
from xml.dom import minidom
from datetime import datetime
from typing import List, Dict
import logging
import traceback

logger = logging.getLogger(__name__)

def get_template():
    with open('template/report.md', 'r', encoding='utf-8') as file:
        return file.read()

def fix_markdown_format(markdown_content: str) -> str:
    """
    ä¿®å¤markdownå†…å®¹æ ¼å¼ï¼Œç¡®ä¿æ ‡é¢˜ã€æ¢è¡Œã€ç¼©è¿›ç­‰æ ¼å¼æ­£ç¡®
    
    Args:
        markdown_content: åŸå§‹markdownå†…å®¹
        
    Returns:
        str: æ ¼å¼åŒ–åçš„markdownå†…å®¹
    """
    if not markdown_content:
        return ""
    
    import re
    
    # 1. ç§»é™¤æ‰€æœ‰æ§åˆ¶å­—ç¬¦
    markdown_content = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', markdown_content)
    
    # 2. ä¿®å¤æ ‡é¢˜æ ¼å¼ï¼šç¡®ä¿æ‰€æœ‰é¢„æœŸçš„æ ‡é¢˜éƒ½æœ‰æ­£ç¡®çš„## å‰ç¼€
    expected_sections = ['æ¼æ´æ¦‚è¿°', 'æœ‰æ•ˆæ€§åˆ†æ', 'æŠ•æ¯’é£é™©åˆ†æ', 'åˆ©ç”¨æ–¹å¼', 'ä»£ç åˆ†æ']
    for section in expected_sections:
        # åŒ¹é…å„ç§å¯èƒ½çš„æ ‡é¢˜æ ¼å¼ï¼Œå¦‚"# æ¼æ´æ¦‚è¿°"ã€"æ¼æ´æ¦‚è¿°"ç­‰
        markdown_content = re.sub(r'#*\s*' + re.escape(section), f'## {section}', markdown_content)
    
    # 3. ç¡®ä¿æ ‡é¢˜ä¹‹é—´æœ‰æ­£ç¡®çš„æ¢è¡Œ
    for section in expected_sections:
        # åœ¨æ ‡é¢˜å‰æ·»åŠ ä¸¤ä¸ªæ¢è¡Œç¬¦ï¼Œç¡®ä¿æ ‡é¢˜ä¹‹é—´æœ‰æ­£ç¡®çš„åˆ†éš”
        markdown_content = re.sub(r'(?<!\n\n)##\s*' + re.escape(section), f'\n\n## {section}', markdown_content)
    
    # 4. ç¡®ä¿æ ‡é¢˜åæœ‰æ­£ç¡®çš„å†…å®¹åˆ†éš”
    for section in expected_sections:
        # åœ¨æ ‡é¢˜åæ·»åŠ ä¸¤ä¸ªæ¢è¡Œç¬¦ï¼Œç¡®ä¿å†…å®¹æ­£ç¡®åˆ†éš”
        markdown_content = re.sub(r'(##\s*' + re.escape(section) + r')([^\n])', r'\1\n\n\2', markdown_content)
    
    # 5. ä¿®å¤åˆ—è¡¨æ ¼å¼ï¼šç¡®ä¿åºå·åˆ—è¡¨é¡¹ä¹‹é—´æœ‰æ­£ç¡®çš„æ¢è¡Œ
    # åŒ¹é… 1. 2. 3. ç­‰åºå·åˆ—è¡¨é¡¹ï¼Œç¡®ä¿å®ƒä»¬ä¹‹é—´æœ‰æ¢è¡Œ
    markdown_content = re.sub(r'(\d+\.\s+[^\d]+?)(?=\d+\.\s+)', r'\1\n', markdown_content)
    
    # 6. ä¿®å¤æ— åºåˆ—è¡¨æ ¼å¼ï¼šç¡®ä¿- åˆ—è¡¨é¡¹ä¹‹é—´æœ‰æ­£ç¡®çš„æ¢è¡Œ
    # åŒ¹é… - å¼€å¤´çš„åˆ—è¡¨é¡¹ï¼Œç¡®ä¿å®ƒä»¬ä¹‹é—´æœ‰æ¢è¡Œ
    markdown_content = re.sub(r'(-\s+[^-]+?)(?=-\s+)', r'\1\n', markdown_content)
    
    # 7. ä¿®å¤"ä»£ç æ‰§è¡Œæµç¨‹ï¼š"ç­‰æè¿°æ€§æ–‡æœ¬åé¢çš„æ¢è¡Œ
    markdown_content = re.sub(r'(ä»£ç æ‰§è¡Œæµç¨‹ï¼š|ä¸»è¦ç»„ä»¶åŒ…æ‹¬ï¼š|æ‰§è¡Œæµç¨‹ï¼š)', r'\1\n', markdown_content)
    
    # 8. ç¡®ä¿åˆ—è¡¨é¡¹å‰æœ‰é€‚å½“çš„æ¢è¡Œ
    markdown_content = re.sub(r'(?<!\n\n)(\d+\.\s+|-\s+)', r'\n\1', markdown_content)
    
    # 9. ç§»é™¤è¡Œé¦–å’Œè¡Œå°¾çš„å¤šä½™ç©ºæ ¼
    markdown_content = '\n'.join([line.strip() for line in markdown_content.split('\n')])
    
    # 10. ç§»é™¤é‡å¤çš„æ¢è¡Œï¼Œç¡®ä¿æœ€å¤šåªæœ‰ä¸¤ä¸ªè¿ç»­æ¢è¡Œ
    markdown_content = re.sub(r'\n{3,}', '\n\n', markdown_content)
    
    # 11. ç‰¹æ®Šå¤„ç†ï¼šç¡®ä¿æ¦‚è¦éƒ¨åˆ†ä¸åŒ…å«ä¸»æ ‡é¢˜
    # ç§»é™¤å¯èƒ½å­˜åœ¨çš„ä¸»æ ‡é¢˜ï¼ˆ# å¼€å¤´çš„è¡Œï¼‰
    markdown_content = re.sub(r'^#\s+[^\n]+\n', '', markdown_content, flags=re.MULTILINE)
    
    # 12. ç¡®ä¿å†…å®¹å¼€å¤´æ²¡æœ‰ç©ºè¡Œ
    markdown_content = markdown_content.lstrip('\n')
    
    # 13. ç¡®ä¿å†…å®¹ç»“å°¾æ²¡æœ‰ç©ºè¡Œ
    markdown_content = markdown_content.rstrip('\n')
    
    return markdown_content

def write_to_markdown(data: Dict, filename: str):
    """
    å°†å†…å®¹å†™å…¥markdownæ–‡ä»¶
    """
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        # è®°å½•å†™å…¥å‰çš„æ•°æ®
        logger.info(f"ğŸ“ å‡†å¤‡å†™å…¥markdown: {filename}")
        logger.debug(f"æ•°æ®å­—æ®µ: {list(data.keys())}")
        
        # ç¡®ä¿æ‰€æœ‰æ¨¡æ¿éœ€è¦çš„å­—æ®µéƒ½å­˜åœ¨ï¼Œæ·»åŠ é»˜è®¤å€¼
        data_with_defaults = data.copy()
        
        # æ·»åŠ related_articleså­—æ®µçš„é»˜è®¤å€¼
        if 'related_articles' not in data_with_defaults:
            data_with_defaults['related_articles'] = 'æš‚æ— ç›¸å…³æ–‡ç« '
        
        # ä¿®å¤æ¦‚è¦å†…å®¹æ ¼å¼
        if 'markdown' in data_with_defaults:
            markdown_content = data_with_defaults['markdown']
            # ä½¿ç”¨ç‹¬ç«‹çš„æ ¼å¼åŒ–å‡½æ•°ä¿®å¤markdownæ ¼å¼
            markdown_content = fix_markdown_format(markdown_content)
            # æ›´æ–°ä¿®å¤åçš„å†…å®¹
            data_with_defaults['markdown'] = markdown_content
        
        template = get_template()
        content = template.format(**data_with_defaults)
        
        with open(filename, 'w', encoding='utf-8') as file:
            file.write(content)
        
        logger.info(f"âœ… Markdownæ–‡ä»¶å·²æˆåŠŸå†™å…¥: {filename}")
        
    except KeyError as e:
        logger.error(f"âŒ æ¨¡æ¿å­—æ®µç¼ºå¤±: {e}")
        logger.error(f"å¯ç”¨å­—æ®µ: {list(data.keys())}")
        logger.error(f"ç¼ºå°‘çš„å­—æ®µå¯èƒ½æ˜¯æ¨¡æ¿ä¸­çš„: {e}")
        raise
    except Exception as e:
        logger.error(f"âŒ å†™å…¥markdownå¤±è´¥: {e}")
        logger.debug(traceback.format_exc())
        raise

def generate_rss_feed(vulnerabilities: List[Dict], title: str, description: str) -> str:
    """
    ç”ŸæˆRSSè®¢é˜…æºXMLå†…å®¹
    """
    # åˆ›å»ºæ ¹å…ƒç´ 
    rss = ET.Element('rss', version='2.0')
    channel = ET.SubElement(rss, 'channel')
    
    # æ·»åŠ é¢‘é“ä¿¡æ¯
    ET.SubElement(channel, 'title').text = title
    ET.SubElement(channel, 'description').text = description
    ET.SubElement(channel, 'link').text = 'http://vulnwatchdog.local'
    ET.SubElement(channel, 'lastBuildDate').text = datetime.now().strftime('%a, %d %b %Y %H:%M:%S +0800')
    ET.SubElement(channel, 'generator').text = 'VulnWatchdog'
    
    # æ·»åŠ æ¯ä¸ªæ¼æ´ä½œä¸ºä¸€ä¸ªæ¡ç›®
    for vuln in vulnerabilities:
        item = ET.SubElement(channel, 'item')
        
        # åŸºæœ¬ä¿¡æ¯
        ET.SubElement(item, 'title').text = f"{vuln.get('cve_id', 'Unknown')} - {vuln.get('title', 'Untitled')}"
        
        # æ„å»ºæè¿°å†…å®¹
        desc_parts = []
        desc_parts.append(f"<strong>ä¸¥é‡ç¨‹åº¦:</strong> {vuln.get('severity', 'Unknown')}")
        desc_parts.append(f"<strong>å‘å¸ƒæ—¥æœŸ:</strong> {vuln.get('published_date', 'Unknown')}")
        desc_parts.append(f"<strong>æ¥æº:</strong> {vuln.get('source', 'Unknown')}")
        desc_parts.append(f"<strong>æè¿°:</strong> {vuln.get('description', 'No description available')}")
        
        # æ·»åŠ PoCä¿¡æ¯
        poc_info = vuln.get('poc_info', [])
        if poc_info:
            desc_parts.append("<strong>ç›¸å…³PoC:</strong>")
            for poc in poc_info:
                repo = poc.get('repo', {})
                if repo:
                    name = repo.get('name', 'Unknown')
                    url = repo.get('html_url', '#')
                    desc = repo.get('description', '')
                    desc_parts.append(f"<a href='{url}'>{name}</a>: {desc}")
        
        description_text = '<br>'.join(desc_parts)
        ET.SubElement(item, 'description').text = description_text
        
        # é“¾æ¥å’Œå”¯ä¸€ID
        link = vuln.get('reference_url', f"https://nvd.nist.gov/vuln/detail/{vuln.get('cve_id', 'unknown')}")
        ET.SubElement(item, 'link').text = link
        ET.SubElement(item, 'guid', isPermaLink='false').text = vuln.get('cve_id', f"unknown-{hash(link)}")
        
        # å‘å¸ƒæ—¥æœŸ
        pub_date = vuln.get('published_date', datetime.now().isoformat())
        ET.SubElement(item, 'pubDate').text = str(pub_date)
    
    # å°†ElementTreeè½¬æ¢ä¸ºç¾è§‚çš„XMLå­—ç¬¦ä¸²
    rough_string = ET.tostring(rss, encoding='utf-8', method='xml')
    reparsed = minidom.parseString(rough_string)
    
    return reparsed.toprettyxml(indent="  ")
